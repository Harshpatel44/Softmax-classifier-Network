{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYsLTfOOJ7E/kx+CsWLFeK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshpatel44/Softmax-classifier-Network/blob/master/softmax-classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AvDl_8om-1FZ",
        "colab": {}
      },
      "source": [
        "def single_from_one_hot(z):\n",
        "    return np.argmax(z,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3wez6mmUQFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_decision(obj,X,numOutputs):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "    ar=np.array([xx.ravel(), yy.ravel()])   \n",
        "    for i in range(numOutputs+1):   # adding column for bias and label for consistency\n",
        "      ar=np.append(ar,np.zeros((1,ar.shape[1]))+1,axis=0)\n",
        "    z = obj.predict(ar.T,1)\n",
        "    z = z[:,0].reshape(xx.shape)\n",
        "    plt.contourf(xx,yy,z)\n",
        "    plt.scatter(X[:,0],X[:,1],c=X[:,-1])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo0rm553UUDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(data,tr_percent,te_percent):\n",
        "    n=np.round((data.shape[0] * tr_percent) / 100)\n",
        "    return data[0:int(n),:-1],data[0:int(n),-1],data[int(n):,:-1],data[int(n):,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk-31sxlgftR",
        "colab_type": "text"
      },
      "source": [
        "# Ek Naya Daur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-CrnIUsgGPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "mnist = datasets.fetch_openml('mnist_784')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnsh9RxZEbRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encoding(X,classes):\n",
        "  one_hot_X=np.zeros((X.shape[0],classes))\n",
        "  one_hot_X[range(X.shape[0]),np.array(X[:,-1],dtype='int8')] = 1\n",
        "  X=np.array(X[:,:-1])\n",
        "  X=np.append(X,one_hot_X,axis=1)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbEF9vRKgIRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = mnist.data[:60000,:]\n",
        "test =  mnist.data[60000:,:]\n",
        "train_y = mnist.target[:60000]\n",
        "test_y =  mnist.target[60000:]\n",
        "\n",
        "\n",
        "train_y=train_y.reshape((train_y.shape[0],1))\n",
        "test_y=test_y.reshape((test_y.shape[0],1))\n",
        "train_y= np.array(train_y,dtype=\"float32\")\n",
        "test_y= np.array(test_y,dtype=\"float32\")\n",
        "\n",
        "\n",
        "train_y=one_hot_encoding(train_y,10)\n",
        "test_y=one_hot_encoding(test_y,10)\n",
        "train=np.clip(train_data,0,1)\n",
        "test=np.clip(test_data,0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjPMc-CHLanu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b4e0eb5-5c4e-4eb0-e072-ba82f6bfaa2f"
      },
      "source": [
        "print(train_y[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2FZVJP2S_7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ac0c98a-d0ab-46b0-ed90-a870149d3aec"
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.hidden_units=5\n",
        "        self.train=train\n",
        "        self.learning_rate=0.01\n",
        "        self.output_classes=10\n",
        "        \n",
        "    def init_weights(self):\n",
        "        self.w1=np.random.rand(self.train.shape[1],self.hidden_units)\n",
        "        self.b1=np.zeros((self.train.shape[0],self.hidden_units))\n",
        "        self.w2=np.random.rand(self.hidden_units,self.hidden_units)\n",
        "        self.b2=np.zeros((self.train.shape[0],self.hidden_units))\n",
        "        self.w3=np.random.rand(self.hidden_units,self.output_classes)\n",
        "        self.b3=np.zeros((self.train.shape[0],self.output_classes))\n",
        "\n",
        "    def loss(self,y,t):\n",
        "        return -np.sum(t * np.log(y))\n",
        "\n",
        "    def activ(self,z):\n",
        "        return np.exp(z - np.max(z,axis=1,keepdims=True))/np.sum(np.exp(z-np.max(z,axis=1,keepdims=True)))\n",
        "\n",
        "    def deriv_activ(self,z,n='r'):\n",
        "        if(n==\"r\"):\n",
        "            return np.where(z>0,1,0)\n",
        "\n",
        "    def train_model(self,train,train_y):\n",
        "        \n",
        "        for i in range(5000):\n",
        "          \n",
        "            h1=self.activ(np.dot(self.train,self.w1,)+self.b1)\n",
        "            h2=self.activ(np.dot(h1,self.w2)+self.b2)\n",
        "            y=self.activ(np.dot(h2,self.w3)+self.b3)\n",
        "            l=self.loss(y,train_y)\n",
        "\n",
        "            print(l)\n",
        "            # derivative for softmax and cross entropy loss together\n",
        "            dl = y - train_y                             # [60k x 10]\n",
        "\n",
        "            #w3/dl\n",
        "            w3_ = np.dot(h2.T,dl)                        # [5 x 60k] x [60k x 10] = [5 x 10] \n",
        "            b3_ = dl\n",
        "\n",
        "            #w2/dl\n",
        "            dz3_=np.dot(dl,self.w3.T)                    # [60k x 10] x [10 x 5] = [60k x 5]\n",
        "            dh2_=np.multiply(dz3_,self.deriv_activ(h2))  # [60k x 5] * [60 x 5]  = [60k x 5]\n",
        "            w2_=np.dot(h1.T,dh2_)                        # [5 X 60k] x [60k x 5] = [5 x 5]\n",
        "            b2_=dh2_\n",
        "\n",
        "            #w1/dl\n",
        "            dz2_=np.dot(dh2_,self.w2.T)                   # [60k x 5] x [5 x 5] = [60k x 5]\n",
        "            dh1_ =np.multiply(dz2_,self.deriv_activ(h1))  # [60k x 5] * [60k x 5] = [60k x 5]\n",
        "            w1_=np.dot(self.train.T,dh1_)                 # [784 x 60k] * [60k x 5] = [784 x 5]\n",
        "            b1_=dh2_\n",
        "         \n",
        "            # self.w3+= np.divide( (-self.learning_rate * w3_) , np.max(self.w3,axis=1,keepdims=True) )\n",
        "            # self.w2+= np.divide( (-self.learning_rate * w2_) , np.max(self.w2,axis=1,keepdims=True) )\n",
        "            # self.w1+= np.divide( (-self.learning_rate * w1_) , np.max(self.w1,axis=1,keepdims=True) )\n",
        "            \n",
        "            self.w3+= (-self.learning_rate * w3_)\n",
        "            self.w2+= (-self.learning_rate * w2_)\n",
        "            self.w1+= (-self.learning_rate * w1_)\n",
        "            \n",
        "            self.b3+= (-self.learning_rate * b3_) \n",
        "            self.b2+= (-self.learning_rate * b2_) \n",
        "            self.b1+= (-self.learning_rate * b1_) \n",
        "    def test_model(self,test,test_y)\n",
        "\n",
        "\n",
        "net=Model()\n",
        "net.train_model(train,train_y)\n",
        "net.test_model(test,test_y)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "798281.0965501452\n",
            "797741.3665407997\n",
            "797202.1808772808\n",
            "796663.5439170689\n",
            "796125.4600422075\n",
            "795587.9336594472\n",
            "795050.9692002129\n",
            "794514.5711205417\n",
            "793978.7439010338\n",
            "793443.4920467808\n",
            "792908.8200873112\n",
            "792374.732576511\n",
            "791841.2340925521\n",
            "791308.32923781\n",
            "790776.0226387917\n",
            "790244.3189460273\n",
            "789713.2228339945\n",
            "789182.7390010075\n",
            "788652.8721691234\n",
            "788123.6270840231\n",
            "787595.0085149137\n",
            "787067.0212543901\n",
            "786539.6701183311\n",
            "786012.9599457544\n",
            "785486.8955986936\n",
            "784961.4819620535\n",
            "784436.7239434664\n",
            "783912.6264731406\n",
            "783389.1945037106\n",
            "782866.4330100623\n",
            "782344.3469891819\n",
            "781822.9414599736\n",
            "781302.2214630772\n",
            "780782.1920606972\n",
            "780262.8583363987\n",
            "779744.2253949197\n",
            "779226.2983619624\n",
            "778709.0823839927\n",
            "778192.5826280158\n",
            "777676.8042813615\n",
            "777161.7525514591\n",
            "776647.4326655993\n",
            "776133.8498706957\n",
            "775621.0094330405\n",
            "775108.9166380469\n",
            "774597.5767900018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-9fc53537f614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-9fc53537f614>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#print(self.w1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#print(self.b1[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mh1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m#print(h1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mh2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVUelkQzt1jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}